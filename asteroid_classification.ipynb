{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Asteroid Classification - Planet Hunt Hackathon\n",
    "\n",
    "# ğŸ“¦ Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ğŸ“… Load Dataset\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"âœ… Data Loaded Successfully\")\n",
    "    print(\"\\nStructure:\\n\", df.info())\n",
    "    print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "    return df\n",
    "\n",
    "# Path to your dataset\n",
    "data_path = \"/content/drive/MyDrive/asteroid_data_analysis/asteroid_data.csv\"\n",
    "df = load_data(data_path)\n",
    "\n",
    "# ğŸ” Drop identifier / non-numeric columns that could cause errors\n",
    "drop_cols = ['name', 'id', 'designation', 'full_name', 'orbit_id']\n",
    "df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# ğŸ” Encode string labels in 'class' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['class'] = label_encoder.fit_transform(df['class'])\n",
    "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"\\u2705 Class label mapping (original â” encoded):\")\n",
    "print(label_map)\n",
    "\n",
    "# ğŸ§¶ Feature Engineering\n",
    "df['MOID_SMA_Ratio'] = df['moid_ld'] / df['a']\n",
    "\n",
    "# ğŸ“Š Descriptive Statistics\n",
    "def analyze_features(data, cols):\n",
    "    for col in cols:\n",
    "        print(f\"\\nğŸ¤ª Stats for {col}:\")\n",
    "        print(f\"Range: {data[col].max() - data[col].min()}\")\n",
    "        print(f\"Mean: {data[col].mean()} | Median: {data[col].median()} | Std: {data[col].std()}\")\n",
    "        sns.histplot(data[col], kde=True)\n",
    "        plt.title(f\"{col} Distribution\")\n",
    "        plt.savefig(f\"{col}_distribution.png\")\n",
    "        plt.clf()\n",
    "\n",
    "main_features = ['H', 'diameter', 'albedo']\n",
    "analyze_features(df, main_features)\n",
    "\n",
    "# ğŸ”„ Normalization Preview\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df[main_features])\n",
    "print(\"\\nğŸ“‰ Scaled Features Preview:\\n\", pd.DataFrame(scaled_features, columns=main_features).head())\n",
    "\n",
    "# ğŸ“ˆ Correlation Plot (Only numeric features)\n",
    "def correlation_plot(data):\n",
    "    numeric_data = data.select_dtypes(include=[np.number])\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(numeric_data.corr(), annot=True, cmap=\"coolwarm\")\n",
    "    plt.title(\"Feature Correlation Heatmap\")\n",
    "    plt.savefig(\"correlation_heatmap.png\")\n",
    "    plt.clf()\n",
    "\n",
    "correlation_plot(df)\n",
    "\n",
    "# ğŸ“… Optional: Detection Methods Heatmap\n",
    "if 'year' in df.columns and 'detection_method' in df.columns:\n",
    "    pivot = df.pivot_table(index='detection_method', columns='year', aggfunc='size', fill_value=0)\n",
    "    sns.heatmap(pivot, cmap=\"YlOrBr\")\n",
    "    plt.title(\"Detection Method Over Years\")\n",
    "    plt.savefig(\"detection_heatmap.png\")\n",
    "    plt.clf()\n",
    "\n",
    "# ğŸ“Œ Class Distribution Before Balancing\n",
    "sns.countplot(x='class', data=df)\n",
    "plt.title(\"Asteroid Class Distribution\")\n",
    "plt.savefig(\"class_countplot.png\")\n",
    "plt.clf()\n",
    "\n",
    "# ğŸ§¼ Prepare Feature Matrix and Target\n",
    "target = 'class'\n",
    "X = df.drop(columns=[target])\n",
    "X = X.select_dtypes(include=[np.number])  # Keep only numeric columns\n",
    "y = df[target]\n",
    "\n",
    "# âš ï¸ Class Imbalance - Before\n",
    "print(\"\\nğŸŒŸ Class Distribution Before SMOTE:\\n\", y.value_counts())\n",
    "\n",
    "class_counts = Counter(y)\n",
    "min_class_count = min(class_counts.values())\n",
    "\n",
    "if min_class_count < 2:\n",
    "    print(\"âŒ SMOTE cannot be applied. A class has less than 2 samples.\")\n",
    "    print(\"âœ… Proceeding without SMOTE. Consider duplicating minority samples manually or dropping rare classes.\")\n",
    "    X_res, y_res = X.copy(), y.copy()  # Just clone data without SMOTE\n",
    "else:\n",
    "    # Safe SMOTE\n",
    "    k_neighbors_value = min(5, min_class_count - 1)\n",
    "    print(f\"âœ… Applying SMOTE with k_neighbors = {k_neighbors_value}\")\n",
    "    smote = SMOTE(random_state=42, k_neighbors=k_neighbors_value)\n",
    "    X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"\\nğŸ“Š Class distribution after SMOTE or fallback:\\n\", pd.Series(y_res).value_counts())\n",
    "\n",
    "# ğŸ“Œ Drop classes with < 2 samples (required for stratify)\n",
    "class_counts = pd.Series(y_res).value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "mask = y_res.isin(valid_classes)\n",
    "X_res = X_res[mask]\n",
    "y_res = y_res[mask]\n",
    "print(\"\\nğŸ“… Class distribution after cleaning:\\n\", y_res.value_counts())\n",
    "\n",
    "# ğŸ” Re-encode target classes after cleaning to ensure XGBoost sees correct label space\n",
    "y_res = pd.Series(LabelEncoder().fit_transform(y_res), index=y_res.index)\n",
    "\n",
    "# ğŸ”€ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, stratify=y_res, random_state=42\n",
    ")\n",
    "\n",
    "# ğŸ¤– Model Training - XGBoost\n",
    "model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=6,\n",
    "                      use_label_encoder=False, eval_metric='mlogloss', verbosity=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ğŸ“ˆ Evaluation Metrics\n",
    "print(\"\\nğŸ“‰ Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nğŸ“” Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ğŸ—ƒï¸ Confusion Matrix Plot\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.clf()\n",
    "\n",
    "# ğŸ” Feature Importance\n",
    "importances = model.feature_importances_\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "feat_names = X.columns[sorted_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances[sorted_indices], y=feat_names)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.savefig(\"feature_importance.png\")\n",
    "plt.clf()\n",
    "\n",
    "print(\"\\nğŸ“¦ All plots saved successfully. Use them in your final PDF report.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
