{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ğŸ“¥ 2. Load Dataset\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"âœ… Data Loaded Successfully\")\n",
    "    print(\"\\nStructure:\\n\", df.info())\n",
    "    print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "    return df\n",
    "\n",
    "data_path = \"C:\\Users\\singh\\OneDrive\\Documents\\Hackathon\\planet hunt\\asteroid_data_analysis\\asteroid_data.csv\" \n",
    "df = load_data(data_path)\n",
    "\n",
    "# ğŸ“Š 3. Descriptive Stats and Feature Insights\n",
    "def analyze_features(data, cols):\n",
    "    for col in cols:\n",
    "        print(f\"\\nğŸ§ª Stats for {col}:\")\n",
    "        print(f\"Range: {data[col].max() - data[col].min()}\")\n",
    "        print(f\"Mean: {data[col].mean()} | Median: {data[col].median()} | Std: {data[col].std()}\")\n",
    "        sns.histplot(data[col], kde=True)\n",
    "        plt.title(f\"{col} Distribution\")\n",
    "        plt.savefig(f\"{col}_distribution.png\")\n",
    "        plt.clf()\n",
    "\n",
    "main_features = ['H', 'diameter', 'albedo']\n",
    "analyze_features(df, main_features)\n",
    "\n",
    "# ğŸ”„ Normalization Check\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df[main_features])\n",
    "print(\"\\nğŸ“‰ Scaled Features Preview:\\n\", pd.DataFrame(scaled_features, columns=main_features).head())\n",
    "\n",
    "# ğŸ“ˆ 4. Visual Exploration\n",
    "def correlation_plot(data):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\")\n",
    "    plt.title(\"Feature Correlation Heatmap\")\n",
    "    plt.savefig(\"correlation_heatmap.png\")\n",
    "    plt.clf()\n",
    "\n",
    "correlation_plot(df)\n",
    "\n",
    "# Optional: Detection heatmap if applicable\n",
    "if 'year' in df.columns and 'detection_method' in df.columns:\n",
    "    pivot = df.pivot_table(index='detection_method', columns='year', aggfunc='size', fill_value=0)\n",
    "    sns.heatmap(pivot, cmap=\"YlOrBr\")\n",
    "    plt.title(\"Detection Method Over Years\")\n",
    "    plt.savefig(\"detection_heatmap.png\")\n",
    "    plt.clf()\n",
    "\n",
    "# Class distribution\n",
    "sns.countplot(x='class', data=df)\n",
    "plt.title(\"Asteroid Class Distribution\")\n",
    "plt.savefig(\"class_countplot.png\")\n",
    "plt.clf()\n",
    "\n",
    "# ğŸ› ï¸ 5. Feature Engineering\n",
    "df['MOID_SMA_Ratio'] = df['moid_ld'] / df['a']\n",
    "\n",
    "# Drop non-numeric identifiers\n",
    "df.drop(columns=['name', 'id'], inplace=True, errors='ignore')\n",
    "\n",
    "# ğŸ¯ 6. Handle Class Imbalance with SMOTE\n",
    "target = 'class'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "print(\"\\nğŸ¯ Class Distribution Before SMOTE:\\n\", y.value_counts())\n",
    "\n",
    "oversampler = SMOTE(random_state=42)\n",
    "X_res, y_res = oversampler.fit_resample(X, y)\n",
    "\n",
    "print(\"\\nğŸ“Š After SMOTE:\\n\", pd.Series(y_res).value_counts())\n",
    "\n",
    "# ğŸ”€ 7. Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, stratify=y_res, random_state=42)\n",
    "\n",
    "# âš™ï¸ 8. XGBoost Classifier\n",
    "model = XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=6,\n",
    "                      use_label_encoder=False, eval_metric='mlogloss', verbosity=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ğŸ“ 9. Evaluation Metrics\n",
    "print(\"\\nâœ… Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nğŸ“„ Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_mat, annot=True, cmap='Blues', fmt='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.clf()\n",
    "\n",
    "# ğŸ” Feature Importance\n",
    "importances = model.feature_importances_\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "feat_names = X.columns[sorted_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances[sorted_indices], y=feat_names)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.savefig(\"feature_importance.png\")\n",
    "plt.clf()\n",
    "\n",
    "print(\"\\n All plots and analysis completed. Use them in your final PDF report.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
